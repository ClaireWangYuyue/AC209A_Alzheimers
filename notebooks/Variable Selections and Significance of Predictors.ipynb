{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/ADNIMERGE_train.csv\")\n",
    "df_test = pd.read_csv(\"data/ADNIMERGE_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = df_train.drop(['RID', 'DX_bl'], axis=1).copy()\n",
    "y_train = df_train['DX_bl'].copy()\n",
    "X_test = df_test.drop(['RID', 'DX_bl'], axis=1).copy()\n",
    "y_test = df_test['DX_bl'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significance of Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to find out the most significant variables in the model. There variables have the strongest predicting power, and are thus the most useful in the diagnosis of Alzheimer's disease. Identifying these variables can eliminate the number of tests a patient has to go through to accurately diagnose AD. \n",
    "\n",
    "For logistic regression with l1 regularization, we used bootstraping (1000 iterations) to find the most significant predictors. For random forest, we used the returned attribute `feature_importances_`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most significant coefficients: \n",
      "Index(['ADAS13', 'MMSE', 'FAQ'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "log_l1 = LogisticRegressionCV(penalty = 'l1', solver = 'liblinear')\n",
    "log_l1.fit(X_train,y_train)\n",
    "c = log_l1.C_[0]\n",
    "\n",
    "\n",
    "iterations = 200\n",
    "boot = np.zeros((X_train.shape[1], iterations))\n",
    "for i in range(iterations):\n",
    "    boot_rows = np.random.choice(range(X_train.shape[0]),\n",
    "                                 size=X_train.shape[0], replace=True)\n",
    "    X_train_boot = X_train.values[boot_rows]\n",
    "    y_train_boot = y_train.values[boot_rows]\n",
    "    model_boot = LogisticRegression(penalty = 'l1', C=c)\n",
    "    model_boot.fit(X_train_boot, y_train_boot)\n",
    "    boot[:,i] = model_boot.coef_[2,:]\n",
    "    \n",
    "boot_ci_upper = np.percentile(boot, 97.5, axis=1)\n",
    "boot_ci_lower = np.percentile(boot, 2.5, axis=1)\n",
    "sig_b_ct = []\n",
    "for i in range(X_train.shape[1]):\n",
    "    if boot_ci_upper[i]<0 or boot_ci_lower[i]>0:\n",
    "        sig_b_ct.append(i)\n",
    "        \n",
    "print(\"Most significant coefficients: \")\n",
    "print(X_train.columns[sig_b_ct])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, we only have 3 significant predictors using bootstrap method, `ADAS13` and `MMSE` (Mini-Mental State Examination) are both cognitive assessments which are likely to be free or cheap. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most important 70 features:\n",
      "['PTGENDER' 'PTEDUCAT' 'PTRACCAT_Asian' 'PTRACCAT_Black' 'PTRACCAT_White'\n",
      " 'PTETHCAT_Not_Hisp/Latino' 'PTMARRY_Never_married' 'PTMARRY_Widowed'\n",
      " 'APOE4' 'CSF_ABETA' 'CSF_TAU' 'CSF_PTAU' 'FDG' 'FDG_slope' 'AV45'\n",
      " 'AV45_slope' 'ADAS13' 'ADAS13_slope' 'MMSE' 'MMSE_slope' 'RAVLT_immediate'\n",
      " 'RAVLT_immediate_slope' 'RAVLT_learning' 'RAVLT_learning_slope'\n",
      " 'RAVLT_forgetting' 'RAVLT_forgetting_slope' 'RAVLT_perc_forgetting'\n",
      " 'RAVLT_perc_forgetting_slope' 'MOCA' 'MOCA_slope' 'EcogPtMem'\n",
      " 'EcogPtMem_slope' 'EcogPtLang' 'EcogPtLang_slope' 'EcogPtVisspat'\n",
      " 'EcogPtVisspat_slope' 'EcogPtPlan' 'EcogPtPlan_slope' 'EcogPtOrgan'\n",
      " 'EcogPtOrgan_slope' 'EcogPtDivatt' 'EcogPtDivatt_slope' 'EcogSPMem'\n",
      " 'EcogSPMem_slope' 'EcogSPLang' 'EcogSPLang_slope' 'EcogSPVisspat'\n",
      " 'EcogSPVisspat_slope' 'EcogSPPlan' 'EcogSPPlan_slope' 'EcogSPOrgan'\n",
      " 'EcogSPOrgan_slope' 'EcogSPDivatt' 'EcogSPDivatt_slope' 'FAQ' 'FAQ_slope'\n",
      " 'Ventricles' 'Ventricles_slope' 'Hippocampus' 'Hippocampus_slope'\n",
      " 'WholeBrain' 'WholeBrain_slope' 'Entorhinal' 'Entorhinal_slope' 'Fusiform'\n",
      " 'Fusiform_slope' 'MidTemp' 'MidTemp_slope' 'ICV' 'ICV_slope']\n"
     ]
    }
   ],
   "source": [
    "rf_best = RandomForestClassifier(n_estimators=32, max_depth=6)\n",
    "rf_best.fit(X_train, y_train)\n",
    "imp_features = np.array(X_train.columns)[rf_best.feature_importances_!=0]\n",
    "print(\"The most important {} features:\".format(len(imp_features)))\n",
    "print(imp_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using random forest classifier, we ended up with 70 important features. If the slope of certain variable is not an important feature, we can at least avoid going through the same test again and again in each visit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward and Backward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step_forwards_backwards(direction='forward'):\n",
    "    \n",
    "    assert direction in ['forward', 'backward']\n",
    "\n",
    "    predictors = set(X_train.columns)\n",
    "    selected_predictors = set() if direction=='forward' else set(predictors)\n",
    "    \n",
    "    n = X_train.shape[0]\n",
    "    best_acc = np.inf\n",
    "    \n",
    "    best_accuracy = []\n",
    "    best_models = []\n",
    "    \n",
    "    if direction == 'forward':\n",
    "        X = X_train[list(selected_predictors)].values\n",
    "        while (True):\n",
    "            \n",
    "            possible_scores = []\n",
    "            possible_predictors = list(selected_predictors ^ predictors)\n",
    "            \n",
    "            if len(possible_predictors) == 0:\n",
    "                break\n",
    "                \n",
    "            for predictor in possible_predictors:\n",
    "                x_temp = np.concatenate([X, X_train[predictor].values.reshape(-1,1)], axis=1)\n",
    "                rf = RandomForestClassifier(n_estimators=32, max_depth=6)\n",
    "                rf.fit(x_temp, y_train)\n",
    "                scores = rf.score(x_temp, y_train)\n",
    "                possible_scores.append(scores)\n",
    "                \n",
    "            best_predictor_ix = np.argmax(possible_scores)\n",
    "            best_predictor = possible_predictors[best_predictor_ix]\n",
    "            \n",
    "            best_acc = np.max(possible_scores)\n",
    "            best_accuracy.append(best_acc)\n",
    "            \n",
    "            selected_predictors.add(best_predictor)            \n",
    "            X = np.concatenate([X, X_train[best_predictor].values.reshape(-1,1)], axis=1)\n",
    "            best_models.append(list(selected_predictors))\n",
    "\n",
    "    else:\n",
    "\n",
    "        while (True):\n",
    "            possible_scores = []\n",
    "            possible_predictors = list(selected_predictors)\n",
    "\n",
    "            if len(possible_predictors) == 0:\n",
    "                break\n",
    "\n",
    "            for predictor in possible_predictors:\n",
    "                X = np.concatenate([np.ones(n).reshape(-1,1), \n",
    "                                    X_train[list(selected_predictors - set([predictor]))].values], \n",
    "                                   axis=1)\n",
    "                if(X.shape[1] != 0):\n",
    "                    rf = RandomForestClassifier(n_estimators=32, max_depth=6)\n",
    "                    rf.fit(X, y_train)\n",
    "                    scores = rf.score(X, y_train)\n",
    "                    possible_scores.append(scores)\n",
    "\n",
    "            best_predictor_ix = np.argmax(possible_scores)\n",
    "            best_predictor = possible_predictors[best_predictor_ix] \n",
    "\n",
    "            best_acc = possible_scores[best_predictor_ix]\n",
    "            selected_predictors.discard(best_predictor)\n",
    "            \n",
    "            best_accuracy.append(best_acc)\n",
    "            best_models.append(list(selected_predictors))\n",
    "            \n",
    "    index_of_best_accuracy = np.argmax(best_accuracy)\n",
    "\n",
    "    return best_models[index_of_best_accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors selected by forward selection ( 29  predictors): \n",
      " ['APOE4', 'PTMARRY_Married', 'CSF_ABETA', 'MOCA_slope', 'EcogPtLang', 'Ventricles', 'MMSE', 'MidTemp', 'WholeBrain', 'WholeBrain_slope', 'Entorhinal_slope', 'EcogSPLang', 'FAQ', 'PTEDUCAT', 'EcogPtOrgan_slope', 'FAQ_slope', 'EcogPtMem', 'Ventricles_slope', 'EcogPtLang_slope', 'Entorhinal', 'RAVLT_forgetting_slope', 'EcogPtVisspat_slope', 'FDG', 'FDG_slope', 'CSF_PTAU', 'Fusiform_slope', 'EcogPtDivatt', 'EcogSPMem', 'PTRACCAT_Black']\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "Predictors selected by backward selection: ( 29  predictors): \n",
      " ['PTMARRY_Married', 'EcogSPMem_slope', 'PTRACCAT_Unknown', 'CSF_ABETA', 'MOCA_slope', 'EcogPtPlan', 'PTRACCAT_Asian', 'RAVLT_learning_slope', 'MMSE', 'RAVLT_immediate', 'EcogSPPlan_slope', 'PTRACCAT_White', 'MOCA', 'WholeBrain_slope', 'EcogPtDivatt_slope', 'ADAS13', 'Hippocampus', 'EcogPtMem', 'RAVLT_forgetting', 'EcogPtLang_slope', 'Entorhinal', 'RAVLT_forgetting_slope', 'EcogSPVisspat_slope', 'FDG_slope', 'Fusiform', 'Fusiform_slope', 'EcogSPMem', 'PTRACCAT_Black', 'APOE4', 'RAVLT_immediate_slope', 'PTRACCAT_More_than_one', 'Ventricles', 'EcogPtPlan_slope', 'RAVLT_perc_forgetting', 'CSF_TAU', 'EcogPtOrgan', 'RAVLT_perc_forgetting_slope', 'Entorhinal_slope', 'EcogSPLang', 'PTETHCAT_Not_Hisp/Latino', 'FAQ', 'RAVLT_learning', 'AV45', 'PTEDUCAT', 'MMSE_slope', 'EcogSPPlan', 'EcogPtOrgan_slope', 'EcogSPDivatt_slope', 'Ventricles_slope', 'EcogPtMem_slope', 'EcogPtVisspat_slope', 'EcogSPOrgan', 'PTMARRY_Widowed']\n"
     ]
    }
   ],
   "source": [
    "predictors_forward = step_forwards_backwards(direction='forward')\n",
    "predictors_backward = step_forwards_backwards(direction='backward')\n",
    "print(\"Predictors selected by forward selection (\", \n",
    "      len(predictors_forward), \" predictors): \\n\", predictors_forward)\n",
    "print(\"\\n-----------------------------------------\\n\")\n",
    "print(\"Predictors selected by backward selection: (\", \n",
    "      len(predictors_forward), \" predictors): \\n\", predictors_backward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that genetic analysis such as `APOE4`, CSF biosamples, neuropsychological tests and MRI are the most important varibles in predicting AD. However, only a few variables we get from each of tests are useful, so we do not need to focus on all the testing results. \n",
    "\n",
    "Also, notably, we found that it is necessary to take the cognitive assessments and perform brain scan multiple times to check the progress of cognitive decline and brain atrophy. These are very indicative of AD. For the other categories, one test is sufficient for the diagnosis of AD. Going through the same test multiple times will not increase predictability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
